{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7196839-471a-40f9-a853-dccb8cf85418",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/summary_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     14\u001b[39m CONDITIONS = [\u001b[33m\"\u001b[39m\u001b[33mfixed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33madaptive\u001b[39m\u001b[33m\"\u001b[39m]     \u001b[38;5;66;03m# baseline vs adaptive\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Load aggregated results\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Ensure required columns exist\u001b[39;00m\n\u001b[32m     23\u001b[39m required_cols = {\u001b[33m\"\u001b[39m\u001b[33mcondition\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdisability_profile\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfinal_knowledge\u001b[39m\u001b[33m\"\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'results/summary_all.csv'"
     ]
    }
   ],
   "source": [
    "# scripts/generate_table_5_1.py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "RESULTS_DIR = Path(\"results\")          # where analyze_batch.py outputs CSV\n",
    "INPUT_FILE = RESULTS_DIR / \"summary_all.csv\"\n",
    "OUTPUT_FILE = RESULTS_DIR / \"table_5_1_final_knowledge.csv\"\n",
    "\n",
    "CONDITIONS = [\"fixed\", \"adaptive\"]     # baseline vs adaptive\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Load aggregated results\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_cols = {\"condition\", \"disability_profile\", \"final_knowledge\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in input CSV: {missing}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Filter to baseline and adaptive conditions\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "df = df[df[\"condition\"].isin(CONDITIONS)]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Aggregate mean ± SD of final knowledge\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "table = (\n",
    "    df.groupby([\"disability_profile\", \"condition\"])[\"final_knowledge\"]\n",
    "      .agg([\"mean\", \"std\"])\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Format as \"mean ± sd\"\n",
    "table[\"Final Knowledge (mean ± SD)\"] = (\n",
    "    table[\"mean\"].round(3).astype(str)\n",
    "    + \" ± \"\n",
    "    + table[\"std\"].round(3).astype(str)\n",
    ")\n",
    "\n",
    "# Pivot for readability\n",
    "table = table.pivot(\n",
    "    index=\"disability_profile\",\n",
    "    columns=\"condition\",\n",
    "    values=\"Final Knowledge (mean ± SD)\"\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns for publication\n",
    "table.columns = [\n",
    "    \"Learner Profile\",\n",
    "    \"Baseline Tutor\",\n",
    "    \"Adaptive Tutor\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Save Table 5.1\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "table.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"\\nTable 5.1 generated successfully:\")\n",
    "print(table)\n",
    "print(f\"\\nSaved to: {OUTPUT_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2520ce45-3be7-4a79-b92e-21bf7dcc12ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find a disability/profile column. Columns: ['source_file', 'condition', 'n_steps', 'knowledge_start', 'knowledge_end', 'knowledge_gain', 'success_rate', 'mean_error_rate', 'mean_cognitive_load', 'mean_response_time', 'cum_reward', 'mean_reward']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a condition column. Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m col_profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a disability/profile column. Columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# If final knowledge is not present, try to reconstruct it from initial + gain\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m col_final_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Could not find a disability/profile column. Columns: ['source_file', 'condition', 'n_steps', 'knowledge_start', 'knowledge_end', 'knowledge_gain', 'success_rate', 'mean_error_rate', 'mean_cognitive_load', 'mean_response_time', 'cum_reward', 'mean_reward']"
     ]
    }
   ],
   "source": [
    "# scripts/generate_table_5_1_from_ch5_run_metrics_selected.py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG: set your input/output\n",
    "# -----------------------------\n",
    "INPUT_FILE = Path(\"/home/alton/alc_logs/final/ch5_run_metrics_selected.csv\")\n",
    "OUTPUT_FILE = Path(\"/home/alton/alc_logs/final/table_5_1_final_knowledge_baseline_vs_adaptive.csv\")\n",
    "\n",
    "BASELINE_NAMES = {\"baseline\", \"fixed\"}   # some pipelines label baseline as \"fixed\"\n",
    "ADAPTIVE_NAMES = {\"adaptive\"}\n",
    "\n",
    "# -----------------------------\n",
    "# Load\n",
    "# -----------------------------\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: pick column by candidates\n",
    "# -----------------------------\n",
    "def pick_col(candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Detect key columns (handles slight naming differences)\n",
    "col_condition = pick_col([\"condition\", \"group\", \"policy_mode\"])\n",
    "col_profile   = pick_col([\"disability_profile\", \"disability_profile_param\", \"profile\"])\n",
    "col_final_k   = pick_col([\"final_knowledge\", \"k_final\", \"knowledge_final\", \"final_k\"])\n",
    "\n",
    "if col_condition is None:\n",
    "    raise ValueError(f\"Could not find a condition column. Columns: {list(df.columns)}\")\n",
    "if col_profile is None:\n",
    "    raise ValueError(f\"Could not find a disability/profile column. Columns: {list(df.columns)}\")\n",
    "\n",
    "# If final knowledge is not present, try to reconstruct it from initial + gain\n",
    "if col_final_k is None:\n",
    "    col_k0 = pick_col([\"k_initial\", \"initial_knowledge\", \"knowledge_initial\", \"initial_k\"])\n",
    "    col_gain = pick_col([\"knowledge_gain\", \"learning_gain\", \"gain_k\"])\n",
    "    if col_k0 is None or col_gain is None:\n",
    "        raise ValueError(\n",
    "            \"Could not find final knowledge OR a pair of (initial knowledge + knowledge gain) to reconstruct it.\\n\"\n",
    "            f\"Columns: {list(df.columns)}\"\n",
    "        )\n",
    "    df[\"_final_knowledge\"] = df[col_k0] + df[col_gain]\n",
    "    col_final_k = \"_final_knowledge\"\n",
    "\n",
    "# -----------------------------\n",
    "# Filter to baseline vs adaptive only\n",
    "# -----------------------------\n",
    "df = df.copy()\n",
    "df[col_condition] = df[col_condition].astype(str).str.strip().str.lower()\n",
    "\n",
    "df = df[df[col_condition].isin(BASELINE_NAMES.union(ADAPTIVE_NAMES))].copy()\n",
    "\n",
    "# Normalize names to exactly \"baseline\" and \"adaptive\"\n",
    "df[\"_cond_norm\"] = df[col_condition].apply(lambda x: \"baseline\" if x in BASELINE_NAMES else \"adaptive\")\n",
    "\n",
    "# -----------------------------\n",
    "# Aggregate mean ± SD of final knowledge by profile × condition\n",
    "# -----------------------------\n",
    "agg = (\n",
    "    df.groupby([col_profile, \"_cond_norm\"])[col_final_k]\n",
    "      .agg([\"count\", \"mean\", \"std\"])\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Format \"mean ± SD\" (handle std NaN when count=1)\n",
    "def fmt(mean, std, n):\n",
    "    if pd.isna(std):\n",
    "        return f\"{mean:.3f} ± N/A (n={n})\"\n",
    "    return f\"{mean:.3f} ± {std:.3f} (n={n})\"\n",
    "\n",
    "agg[\"Final Knowledge (mean ± SD)\"] = [\n",
    "    fmt(m, s, n) for m, s, n in zip(agg[\"mean\"], agg[\"std\"], agg[\"count\"])\n",
    "]\n",
    "\n",
    "# Pivot into publication table\n",
    "table = agg.pivot(index=col_profile, columns=\"_cond_norm\", values=\"Final Knowledge (mean ± SD)\").reset_index()\n",
    "\n",
    "# Ensure both columns exist even if one is missing in data\n",
    "if \"baseline\" not in table.columns:\n",
    "    table[\"baseline\"] = \"\"\n",
    "if \"adaptive\" not in table.columns:\n",
    "    table[\"adaptive\"] = \"\"\n",
    "\n",
    "# Rename columns for thesis\n",
    "table = table.rename(columns={\n",
    "    col_profile: \"Learner Profile\",\n",
    "    \"baseline\": \"Baseline Tutor (Final knowledge: mean ± SD)\",\n",
    "    \"adaptive\": \"Adaptive Tutor (Final knowledge: mean ± SD)\"\n",
    "})\n",
    "\n",
    "# Optional: sort profiles nicely if present\n",
    "preferred_order = [\"none\", \"dyslexia\", \"hearing_impairment\", \"low_vision\"]\n",
    "table[\"__order\"] = table[\"Learner Profile\"].astype(str).apply(lambda x: preferred_order.index(x) if x in preferred_order else 999)\n",
    "table = table.sort_values(\"__order\").drop(columns=\"__order\")\n",
    "\n",
    "# Save\n",
    "table.to_csv(OUTPUT_FILE, index=False)-------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[4], line 37\n",
    "     35     raise ValueError(f\"Could not find a condition column. Columns: {list(df.columns)}\")\n",
    "     36 if col_profile is None:\n",
    "---> 37     raise ValueError(f\"Could not find a disability/profile column. Columns: {list(df.columns)}\")\n",
    "     39 # If final knowledge is not present, try to reconstruct it from initial + gain\n",
    "     40 if col_final_k is None:\n",
    "\n",
    "ValueError: Could not find a disability/profile column. Columns: ['source_file', 'condition', 'n_steps', 'knowledge_start', 'knowledge_end', 'knowledge_gain', 'success_rate', 'mean_error_rate', 'mean_cognitive_load', 'mean_response_time', 'cum_reward', 'mean_reward']\n",
    "\n",
    "print(\"\\nTable 5.1 generated successfully.\\n\")\n",
    "print(table.to_string(index=False))\n",
    "print(f\"\\nSaved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d2a7c3-58e3-47e9-acc5-119202bbdb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20260115_080831.csv', '20260115_081028.csv', '20260115_082025.csv', '4b8e83db-5c81-452c-9792-ce02ad5580a7.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/alton/alc_logs/final/ch5_run_metrics_selected.csv\")\n",
    "print(df[\"source_file\"].head(10).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538bebc7-de5c-4711-b311-7b7f0c818724",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find disability_profile for 1 run(s). Example missing run_stem values: ['4b8e83db-5c81-452c-9792-ce02ad5580a7']\nChecked metadata under: /home/alton/alc_logs",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing > \u001b[32m0\u001b[39m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# show a few missing stems to help debug if needed\u001b[39;00m\n\u001b[32m     62\u001b[39m     missing_examples = df.loc[df[\u001b[33m\"\u001b[39m\u001b[33mdisability_profile\u001b[39m\u001b[33m\"\u001b[39m].isna(), \u001b[33m\"\u001b[39m\u001b[33mrun_stem\u001b[39m\u001b[33m\"\u001b[39m].head(\u001b[32m10\u001b[39m).tolist()\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     64\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find disability_profile for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m run(s). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExample missing run_stem values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_examples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     66\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChecked metadata under: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOG_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m     )\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Aggregate: mean ± SD final knowledge by disability_profile × condition\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     72\u001b[39m agg = (\n\u001b[32m     73\u001b[39m     df.groupby([\u001b[33m\"\u001b[39m\u001b[33mdisability_profile\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcondition_norm\u001b[39m\u001b[33m\"\u001b[39m])[\u001b[33m\"\u001b[39m\u001b[33mknowledge_end\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     74\u001b[39m       .agg([\u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     75\u001b[39m       .reset_index()\n\u001b[32m     76\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Could not find disability_profile for 1 run(s). Example missing run_stem values: ['4b8e83db-5c81-452c-9792-ce02ad5580a7']\nChecked metadata under: /home/alton/alc_logs"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "RUN_METRICS = Path(\"/home/alton/alc_logs/final/ch5_run_metrics_selected.csv\")\n",
    "LOG_ROOT = Path(\"/home/alton/alc_logs\")  # where metadata lives\n",
    "OUTPUT = Path(\"/home/alton/alc_logs/final/table_5_1_final_knowledge_by_profile.csv\")\n",
    "\n",
    "BASELINE_NAMES = {\"baseline\", \"fixed\"}\n",
    "ADAPTIVE_NAMES = {\"adaptive\"}\n",
    "\n",
    "# -----------------------------\n",
    "# Load run metrics\n",
    "# -----------------------------\n",
    "df = pd.read_csv(RUN_METRICS)\n",
    "\n",
    "# Normalize condition\n",
    "df[\"condition\"] = df[\"condition\"].astype(str).str.strip().str.lower()\n",
    "df = df[df[\"condition\"].isin(BASELINE_NAMES.union(ADAPTIVE_NAMES))].copy()\n",
    "df[\"condition_norm\"] = df[\"condition\"].apply(lambda x: \"baseline\" if x in BASELINE_NAMES else \"adaptive\")\n",
    "\n",
    "# We'll use knowledge_end as final knowledge (your file has it)\n",
    "if \"knowledge_end\" not in df.columns:\n",
    "    raise ValueError(f\"'knowledge_end' not found in {RUN_METRICS}. Columns: {list(df.columns)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Build a lookup: run_name -> disability_profile from metadata JSON\n",
    "# metadata naming convention: <run_name>_metadata.json\n",
    "# run_name corresponds to CSV filename stem (e.g., 20260115_080831.csv -> 20260115_080831_metadata.json)\n",
    "# -----------------------------\n",
    "# Index metadata by run_name (stem)\n",
    "meta_by_run = {}\n",
    "for meta_path in LOG_ROOT.rglob(\"*_metadata.json\"):\n",
    "    stem = meta_path.name.replace(\"_metadata.json\", \"\")\n",
    "    try:\n",
    "        with meta_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            meta = json.load(f)\n",
    "        # keys per documentation: disability_profile, condition, etc.\n",
    "        disability = meta.get(\"disability_profile\") or meta.get(\"disability_profile_param\") or meta.get(\"profile\")\n",
    "        if disability is not None:\n",
    "            meta_by_run[stem] = disability\n",
    "    except Exception:\n",
    "        # ignore unreadable metadata files\n",
    "        pass\n",
    "\n",
    "# -----------------------------\n",
    "# Attach disability_profile to each row using source_file stem\n",
    "# source_file values: \"20260115_080831.csv\" -> stem \"20260115_080831\"\n",
    "# -----------------------------\n",
    "def infer_run_stem(source_file: str) -> str:\n",
    "    return Path(str(source_file)).stem\n",
    "\n",
    "df[\"run_stem\"] = df[\"source_file\"].astype(str).apply(infer_run_stem)\n",
    "df[\"disability_profile\"] = df[\"run_stem\"].map(meta_by_run)\n",
    "\n",
    "missing = df[\"disability_profile\"].isna().sum()\n",
    "if missing > 0:\n",
    "    # show a few missing stems to help debug if needed\n",
    "    missing_examples = df.loc[df[\"disability_profile\"].isna(), \"run_stem\"].head(10).tolist()\n",
    "    raise ValueError(\n",
    "        f\"Could not find disability_profile for {missing} run(s). \"\n",
    "        f\"Example missing run_stem values: {missing_examples}\\n\"\n",
    "        f\"Checked metadata under: {LOG_ROOT}\"\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# Aggregate: mean ± SD final knowledge by disability_profile × condition\n",
    "# -----------------------------\n",
    "agg = (\n",
    "    df.groupby([\"disability_profile\", \"condition_norm\"])[\"knowledge_end\"]\n",
    "      .agg([\"count\", \"mean\", \"std\"])\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "def fmt(mean, std, n):\n",
    "    if pd.isna(std):\n",
    "        return f\"{mean:.3f} ± N/A (n={int(n)})\"\n",
    "    return f\"{mean:.3f} ± {std:.3f} (n={int(n)})\"\n",
    "\n",
    "agg[\"Final Knowledge (mean ± SD)\"] = [\n",
    "    fmt(m, s, n) for m, s, n in zip(agg[\"mean\"], agg[\"std\"], agg[\"count\"])\n",
    "]\n",
    "\n",
    "table = agg.pivot(\n",
    "    index=\"disability_profile\",\n",
    "    columns=\"condition_norm\",\n",
    "    values=\"Final Knowledge (mean ± SD)\"\n",
    ").reset_index()\n",
    "\n",
    "# Ensure both columns exist\n",
    "if \"baseline\" not in table.columns:\n",
    "    table[\"baseline\"] = \"\"\n",
    "if \"adaptive\" not in table.columns:\n",
    "    table[\"adaptive\"] = \"\"\n",
    "\n",
    "table = table.rename(columns={\n",
    "    \"disability_profile\": \"Learner Profile\",\n",
    "    \"baseline\": \"Baseline Tutor (Final knowledge: mean ± SD)\",\n",
    "    \"adaptive\": \"Adaptive Tutor (Final knowledge: mean ± SD)\"\n",
    "})\n",
    "\n",
    "# Optional ordering\n",
    "preferred = [\"none\", \"dyslexia\", \"hearing_impairment\", \"low_vision\"]\n",
    "table[\"__order\"] = table[\"Learner Profile\"].astype(str).apply(lambda x: preferred.index(x) if x in preferred else 999)\n",
    "table = table.sort_values(\"__order\").drop(columns=\"__order\")\n",
    "\n",
    "# Save\n",
    "table.to_csv(OUTPUT, index=False)\n",
    "\n",
    "print(\"\\nTable 5.1 generated successfully:\\n\")\n",
    "print(table.to_string(index=False))\n",
    "print(f\"\\nSaved to: {OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba1a6a0-32a7-46a7-a68d-1b31b159b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Dropping 1 run(s) with no metadata match.\n",
      "Example missing run_stem values: ['4b8e83db-5c81-452c-9792-ce02ad5580a7']\n",
      "\n",
      "Table 5.1 generated successfully:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Learner Profile, Baseline Tutor (Final knowledge: mean ± SD), Adaptive Tutor (Final knowledge: mean ± SD)]\n",
      "Index: []\n",
      "\n",
      "Saved to: /home/alton/alc_logs/final/table_5_1_final_knowledge_by_profile.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RUN_METRICS = Path(\"/home/alton/alc_logs/final/ch5_run_metrics_selected.csv\")\n",
    "LOG_ROOTS = [Path(\"/home/alton/alc_logs\"), Path(\"/home/alton/alc_logs/final\")]  # search both\n",
    "OUTPUT = Path(\"/home/alton/alc_logs/final/table_5_1_final_knowledge_by_profile.csv\")\n",
    "\n",
    "BASELINE_NAMES = {\"baseline\", \"fixed\"}\n",
    "ADAPTIVE_NAMES = {\"adaptive\"}\n",
    "\n",
    "df = pd.read_csv(RUN_METRICS)\n",
    "\n",
    "df[\"condition\"] = df[\"condition\"].astype(str).str.strip().str.lower()\n",
    "df = df[df[\"condition\"].isin(BASELINE_NAMES.union(ADAPTIVE_NAMES))].copy()\n",
    "df[\"condition_norm\"] = df[\"condition\"].apply(lambda x: \"baseline\" if x in BASELINE_NAMES else \"adaptive\")\n",
    "\n",
    "if \"knowledge_end\" not in df.columns:\n",
    "    raise ValueError(f\"'knowledge_end' not found. Columns: {list(df.columns)}\")\n",
    "\n",
    "# --- Build metadata lookup across possible roots ---\n",
    "meta_by_run = {}\n",
    "for root in LOG_ROOTS:\n",
    "    for meta_path in root.rglob(\"*_metadata.json\"):\n",
    "        stem = meta_path.name.replace(\"_metadata.json\", \"\")\n",
    "        try:\n",
    "            with meta_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                meta = json.load(f)\n",
    "            disability = meta.get(\"disability_profile\") or meta.get(\"disability_profile_param\") or meta.get(\"profile\")\n",
    "            if disability is not None:\n",
    "                meta_by_run[stem] = disability\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "df[\"run_stem\"] = df[\"source_file\"].astype(str).apply(lambda x: Path(x).stem)\n",
    "df[\"disability_profile\"] = df[\"run_stem\"].map(meta_by_run)\n",
    "\n",
    "# --- Drop unmatched rows (instead of failing) ---\n",
    "missing_mask = df[\"disability_profile\"].isna()\n",
    "n_missing = int(missing_mask.sum())\n",
    "if n_missing > 0:\n",
    "    missing_examples = df.loc[missing_mask, \"run_stem\"].unique().tolist()[:10]\n",
    "    print(f\"WARNING: Dropping {n_missing} run(s) with no metadata match.\")\n",
    "    print(f\"Example missing run_stem values: {missing_examples}\")\n",
    "    df = df[~missing_mask].copy()\n",
    "\n",
    "# --- Aggregate ---\n",
    "agg = (\n",
    "    df.groupby([\"disability_profile\", \"condition_norm\"])[\"knowledge_end\"]\n",
    "      .agg([\"count\", \"mean\", \"std\"])\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "def fmt(mean, std, n):\n",
    "    if pd.isna(std):\n",
    "        return f\"{mean:.3f} ± N/A (n={int(n)})\"\n",
    "    return f\"{mean:.3f} ± {std:.3f} (n={int(n)})\"\n",
    "\n",
    "agg[\"Final Knowledge (mean ± SD)\"] = [fmt(m, s, n) for m, s, n in zip(agg[\"mean\"], agg[\"std\"], agg[\"count\"])]\n",
    "\n",
    "table = agg.pivot(index=\"disability_profile\", columns=\"condition_norm\", values=\"Final Knowledge (mean ± SD)\").reset_index()\n",
    "\n",
    "if \"baseline\" not in table.columns:\n",
    "    table[\"baseline\"] = \"\"\n",
    "if \"adaptive\" not in table.columns:\n",
    "    table[\"adaptive\"] = \"\"\n",
    "\n",
    "table = table.rename(columns={\n",
    "    \"disability_profile\": \"Learner Profile\",\n",
    "    \"baseline\": \"Baseline Tutor (Final knowledge: mean ± SD)\",\n",
    "    \"adaptive\": \"Adaptive Tutor (Final knowledge: mean ± SD)\"\n",
    "})\n",
    "\n",
    "preferred = [\"none\", \"dyslexia\", \"hearing_impairment\", \"low_vision\"]\n",
    "table[\"__order\"] = table[\"Learner Profile\"].astype(str).apply(lambda x: preferred.index(x) if x in preferred else 999)\n",
    "table = table.sort_values(\"__order\").drop(columns=\"__order\")\n",
    "\n",
    "table.to_csv(OUTPUT, index=False)\n",
    "\n",
    "print(\"\\nTable 5.1 generated successfully:\\n\")\n",
    "print(table.to_string(index=False))\n",
    "print(f\"\\nSaved to: {OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664bfe67-5b2d-4cbb-bbb6-1535c9c35809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alton/dev/inclusive-alc-sim/results\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f9ff7f-5f25-4de0-bf73-4010c1828c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 5.1 generated successfully:\n",
      "\n",
      "Learner Profile Adaptive Tutor (Final knowledge: mean ± SD) Baseline Tutor (Final knowledge: mean ± SD)\n",
      "       dyslexia                         0.029 ± 0.032 (n=5)                         0.020 ± 0.027 (n=5)\n",
      "\n",
      "Saved to: /home/alton/alc_logs/final/table_5_1_final_knowledge_by_profile.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_ROOT = Path(\"/home/alton/alc_logs/final\")  # <-- your \"final\" folder\n",
    "OUTPUT = Path(\"/home/alton/alc_logs/final/table_5_1_final_knowledge_by_profile.csv\")\n",
    "\n",
    "# Collect candidate run CSVs (exclude summary/table/metrics files)\n",
    "csvs = []\n",
    "for p in LOG_ROOT.rglob(\"*.csv\"):\n",
    "    name = p.name.lower()\n",
    "    if name.endswith(\"_summary.csv\"):\n",
    "        continue\n",
    "    if name.startswith(\"table_\") or \"condition_summary\" in name or \"run_metrics\" in name:\n",
    "        continue\n",
    "    csvs.append(p)\n",
    "\n",
    "if not csvs:\n",
    "    raise ValueError(f\"No run CSVs found under {LOG_ROOT}\")\n",
    "\n",
    "rows = []\n",
    "for p in csvs:\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "\n",
    "        # Required columns from logger outputs (per documentation)\n",
    "        # condition + disability profile + knowledge time series\n",
    "        cond_col = \"condition\" if \"condition\" in df.columns else None\n",
    "        prof_col = \"disability_profile_param\" if \"disability_profile_param\" in df.columns else None\n",
    "        know_col = \"knowledge\" if \"knowledge\" in df.columns else None\n",
    "\n",
    "        if cond_col is None or prof_col is None or know_col is None:\n",
    "            continue\n",
    "\n",
    "        condition = str(df[cond_col].iloc[0]).strip().lower()\n",
    "        profile = str(df[prof_col].iloc[0]).strip().lower()\n",
    "\n",
    "        # Keep only baseline vs adaptive (baseline may appear as fixed/baseline)\n",
    "        if condition not in {\"fixed\", \"baseline\", \"adaptive\"}:\n",
    "            continue\n",
    "        condition = \"baseline\" if condition in {\"fixed\", \"baseline\"} else \"adaptive\"\n",
    "\n",
    "        # Final knowledge = last knowledge value in the run\n",
    "        final_k = float(df[know_col].iloc[-1])\n",
    "\n",
    "        rows.append({\"condition\": condition, \"profile\": profile, \"final_knowledge\": final_k})\n",
    "\n",
    "    except Exception:\n",
    "        # Skip unreadable files\n",
    "        continue\n",
    "\n",
    "data = pd.DataFrame(rows)\n",
    "if data.empty:\n",
    "    raise ValueError(\n",
    "        \"No usable run logs found. \"\n",
    "        \"Check that LOG_ROOT contains the logger output CSVs with columns \"\n",
    "        \"condition, disability_profile_param, knowledge.\"\n",
    "    )\n",
    "\n",
    "# Aggregate mean ± SD by profile × condition\n",
    "agg = (\n",
    "    data.groupby([\"profile\", \"condition\"])[\"final_knowledge\"]\n",
    "        .agg([\"count\", \"mean\", \"std\"])\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "# Format mean ± SD\n",
    "def fmt(mean, std, n):\n",
    "    if pd.isna(std):\n",
    "        return f\"{mean:.3f} ± N/A (n={int(n)})\"\n",
    "    return f\"{mean:.3f} ± {std:.3f} (n={int(n)})\"\n",
    "\n",
    "agg[\"Final Knowledge (mean ± SD)\"] = [\n",
    "    fmt(m, s, n) for m, s, n in zip(agg[\"mean\"], agg[\"std\"], agg[\"count\"])\n",
    "]\n",
    "\n",
    "table = agg.pivot(index=\"profile\", columns=\"condition\", values=\"Final Knowledge (mean ± SD)\").reset_index()\n",
    "\n",
    "# Ensure both columns exist\n",
    "if \"baseline\" not in table.columns:\n",
    "    table[\"baseline\"] = \"\"\n",
    "if \"adaptive\" not in table.columns:\n",
    "    table[\"adaptive\"] = \"\"\n",
    "\n",
    "table = table.rename(columns={\n",
    "    \"profile\": \"Learner Profile\",\n",
    "    \"baseline\": \"Baseline Tutor (Final knowledge: mean ± SD)\",\n",
    "    \"adaptive\": \"Adaptive Tutor (Final knowledge: mean ± SD)\",\n",
    "})\n",
    "\n",
    "# Optional nice ordering\n",
    "preferred = [\"none\", \"dyslexia\", \"hearing_impairment\", \"low_vision\"]\n",
    "table[\"__order\"] = table[\"Learner Profile\"].apply(lambda x: preferred.index(x) if x in preferred else 999)\n",
    "table = table.sort_values(\"__order\").drop(columns=\"__order\")\n",
    "\n",
    "table.to_csv(OUTPUT, index=False)\n",
    "\n",
    "print(\"\\nTable 5.1 generated successfully:\\n\")\n",
    "print(table.to_string(index=False))\n",
    "print(f\"\\nSaved to: {OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b678b9-bd46-4d89-a6b5-ede2ac5db27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 3.12 DL",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
